{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T12:38:14.217158Z",
     "start_time": "2020-01-13T12:38:12.768361Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load/Pre process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T12:38:15.807742Z",
     "start_time": "2020-01-13T12:38:14.399670Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_json(\"arxivData.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T12:38:15.833671Z",
     "start_time": "2020-01-13T12:38:15.811732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We propose an architecture for VQA which utilizes recurrent layers to\\ngenerate visual and textual attention. The memory characteristic of the\\nproposed recurrent attention units offers a rich joint embedding of visual and\\ntextual features and enables the model to reason relations between several\\nparts of the image and question. Our single model outperforms the first place\\nwinner on the VQA 1.0 dataset, performs within margin to the current\\nstate-of-the-art ensemble model. We also experiment with replacing attention\\nmechanisms in other state-of-the-art models with our implementation and show\\nincreased accuracy. In both cases, our recurrent attention mechanism improves\\nperformance in tasks requiring sequential or relational reasoning on the VQA\\ndataset.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T12:38:16.055835Z",
     "start_time": "2020-01-13T12:38:16.048859Z"
    }
   },
   "outputs": [],
   "source": [
    "def prefunc(x):\n",
    "    return re.sub(\"[^a-zA-Z0-9\\.' ]+\", '', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T12:38:17.207178Z",
     "start_time": "2020-01-13T12:38:17.198202Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We propose an architecture for VQA which utilizes recurrent layers togenerate visual and textual attention. The memory characteristic of theproposed recurrent attention units offers a rich joint embedding of visual andtextual features and enables the model to reason relations between severalparts of the image and question. Our single model outperforms the first placewinner on the VQA 1.0 dataset performs within margin to the currentstateoftheart ensemble model. We also experiment with replacing attentionmechanisms in other stateoftheart models with our implementation and showincreased accuracy. In both cases our recurrent attention mechanism improvesperformance in tasks requiring sequential or relational reasoning on the VQAdataset.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefunc(data['summary'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T12:38:22.834219Z",
     "start_time": "2020-01-13T12:38:20.146770Z"
    }
   },
   "outputs": [],
   "source": [
    "data['summary'] = data['summary'].apply(prefunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T12:38:28.923500Z",
     "start_time": "2020-01-13T12:38:24.417703Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T12:38:29.819632Z",
     "start_time": "2020-01-13T12:38:29.810659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'day', 'id', 'link', 'month', 'summary', 'tag', 'title',\n",
       "       'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T12:38:31.046519Z",
     "start_time": "2020-01-13T12:38:30.767600Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T12:47:29.620039Z",
     "start_time": "2020-01-13T12:45:45.961914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data2 = (TextList.from_df(data, cols=5)\n",
    "                .split_by_rand_pct(0.1)\n",
    "               .label_for_lm()  \n",
    "                .databunch(bs=16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T12:47:29.634001Z",
     "start_time": "2020-01-13T12:47:29.624026Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (36900 items)\n",
       "x: LMTextList\n",
       "xxbos xxmaj we propose an architecture for xxup vqa which utilizes recurrent layers togenerate visual and textual attention . xxmaj the memory characteristic of theproposed recurrent attention units offers a rich joint embedding of visual andtextual features and enables the model to reason relations between xxunk of the image and question . xxmaj our single model outperforms the first xxunk on the xxup vqa 1.0 dataset performs within margin to the currentstateoftheart ensemble model . xxmaj we also experiment with replacing attentionmechanisms in other stateoftheart models with our implementation and xxunk accuracy . xxmaj in both cases our recurrent attention mechanism improvesperformance in tasks requiring sequential or relational reasoning on the vqadataset .,xxbos xxmaj recent approaches based on artificial neural networks anns have shownpromising results for shorttext classification . xxmaj however many short xxunk in sequences e.g. sentences in a document or utterances in a dialogand most existing annbased systems do not leverage the preceding short xxunk classifying a subsequent one . xxmaj in this work we present a model based onrecurrent neural networks and convolutional neural networks that incorporatesthe preceding short texts . xxmaj our model achieves stateoftheart results on threedifferent datasets for dialog act prediction .,xxbos xxmaj we introduce the multiresolution recurrent neural network which extends thesequencetosequence framework to model natural language generation as xxunk discrete stochastic processes a sequence of highlevel coarse xxunk a sequence of natural language tokens . xxmaj there are many ways to estimate xxunk the highlevel coarse tokens but we argue that a simple xxunk is sufficient to capture a wealth of highlevel discourse semantics . xxmaj such procedure allows training the multiresolution recurrent neural network bymaximizing the exact joint loglikelihood over both sequences . xxmaj in contrast tothe standard log likelihood objective w.r.t . natural language tokens xxunk optimizing the joint loglikelihood biases the model xxunk highlevel abstractions . xxmaj we apply the proposed model to the task ofdialogue response generation in two challenging domains the xxmaj ubuntu xxunk domain and xxmaj twitter conversations . xxmaj on xxmaj ubuntu the model xxunk approaches by a substantial margin achieving stateoftheartresults according to both automatic evaluation metrics and a human xxunk . xxmaj on xxmaj twitter the model appears to generate more relevant and xxunk according to automatic evaluation metrics . xxmaj finally our experimentsdemonstrate that the proposed model is more adept at overcoming the sparsity ofnatural language and is better able to capture longterm structure .,xxbos xxmaj multitask learning is motivated by the observation that humans bring to xxunk they know about related problems when solving new ones . xxmaj similarly deepneural networks can profit from related tasks by sharing parameters with xxunk . xxmaj however humans do not consciously decide to transfer xxunk tasks . xxmaj in xxmaj natural xxmaj language xxmaj processing xxup nlp it is hard to predict xxunk will lead to improvements particularly if tasks are only xxunk . xxmaj to overcome this we introduce xxmaj sluice xxmaj networks a general frameworkfor multitask learning where trainable parameters control the amount ofsharing . xxmaj our framework generalizes previous proposals in enabling sharing ofall combinations of subspaces layers and skip connections . xxmaj we performexperiments on three task pairs and across seven different domains using datafrom ontonotes 5.0 and achieve up to 15 average error reductions over commonapproaches to multitask learning . xxmaj we show that a label entropy is xxunk gains in sluice networks confirming findings for hard parameter sharing andb while sluice networks easily fit noise they are robust across domains inpractice .,xxbos xxmaj we present xxup milabot a deep reinforcement learning chatbot developed by themontreal xxmaj institute for xxmaj learning xxmaj algorithms xxup xxunk for the xxmaj amazon xxmaj alexa xxmaj xxunk . xxup milabot is capable of conversing with humans on popular small xxunk through both speech and text . xxmaj the system consists of an ensemble ofnatural language generation and retrieval models including xxunk bagofwords models sequencetosequence neural network and latentvariable neural network models . xxmaj by applying reinforcement learning xxunk data and realworld user interactions the system has been trainedto select an appropriate response from the models in its ensemble . xxmaj the systemhas been evaluated through xxup ab testing with realworld users where xxunk significantly better than many competing systems . xxmaj due to its machinelearning architecture the system is likely to improve with additional data .\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (4100 items)\n",
       "x: LMTextList\n",
       "xxbos xxmaj while all kinds of mixed data from personal data over panel and xxunk to public and commercial data are collected and stored xxunk graphical models for these hybrid domains becomes more difficult . xxmaj users spend significant amounts of time in identifying the parametric form ofthe random variables xxmaj gaussian xxmaj poisson xxmaj logit etc . involved and learning themixed models . xxmaj to make this difficult task easier we propose the xxunk probabilistic deep architecture for hybrid domains that xxunk queries . xxmaj it is based on sumproduct xxmaj networks spns with xxunk leave distributions together with novel nonparametric decompositionand conditioning steps using the xxunk xxunk xxmaj coefficient . xxmaj this relieves the user from deciding apriori theparametric form of the random variables but is still expressive enough toeffectively approximate any continuous distribution and permits efficientlearning and inference . xxmaj our empirical evidence shows that the architecturecalled xxmaj mixed spns can indeed capture complex distributions across a wide rangeof hybrid domains .,xxbos xxmaj purpose xxmaj to determine whether deep learningbased algorithms applied xxunk xxup mr images can aid in the prediction of xxunk invasive disease followingthe di xxunk of xxunk carcinoma in situ xxup xxunk by core needle biopsy . xxmaj material and xxmaj methods xxmaj in this institutional review xxunk study weanalyzed dynamic contrastenhanced xxunk xxmaj t1weighted xxup mri sequences xxunk patients at our institution with a core needle xxunk diagnosisof xxup xxunk . xxmaj the patients had no preoperative therapy before breast xxup mri and noprior history of breast cancer . xxmaj we explored two different deep learningapproaches to predict whether there was a hidden xxunk invasive component inthe analyzed tumors that was ultimately detected at surgical excision . xxmaj in thefirst approach we adopted the transfer learning strategy in which a xxunk on a large dataset of natural images is finetuned with our xxunk . xxmaj specifically we used the googlenet model pretrained on the imagenetdataset . xxmaj in the second approach we used a pretrained network to extract deepfeatures and a support vector machine xxup svm that utilizes these features topredict the xxunk of the xxup xxunk . xxmaj we used 10fold cross validation and thearea under the xxup roc curve xxup auc to estimate the performance of the predictivemodels . xxmaj results xxmaj the best classification performance was obtained using thedeep features approach with googlenet model pretrained on imagenet as thefeature extractor and a polynomial kernel xxup svm used as the classifier xxup auc 0.70 95 xxup ci xxunk 0.79 . xxmaj for the transfer learning based approach thehighest xxup auc obtained was 0.53 95 xxup ci xxunk . xxmaj conclusion xxmaj convolutionalneural networks could potentially be used to identify xxunk invasive xxunk patients diagnosed with xxup xxunk at the initial core needle biopsy .,xxbos xxmaj inferring topics from the overwhelming amount of short texts becomes acritical but challenging task for many content analysis tasks such as xxunk user interest profiling and emerging topic detecting . xxmaj existingmethods such as probabilistic latent semantic analysis xxup plsa and latentdirichlet allocation xxup lda can not solve this prob lem very well since onlyvery limited word cooccurrence information is available in short texts . xxmaj thispaper studies how to incorporate the external word correlation knowledge xxunk texts to improve the coherence of topic modeling . xxmaj based on recent resultsin word embeddings that learn se xxunk representations for words from alarge corpus we introduce a novel method xxmaj embeddingbased xxmaj topic xxmaj model xxunk learn latent topics from short texts . xxup etm not only solves the problem ofvery limited word cooccurrence information by aggregating short texts xxunk pseudo texts but also utilizes a xxmaj markov xxmaj random xxmaj field regularized modelthat gives correlated words a better chance to be put into the same topic . xxmaj theexperiments on realworld datasets validate the effectiveness of our xxunk with the stateoftheart models .,xxbos xxmaj networks play a central role in modern data analysis enabling us to reasonabout systems by studying the relationships between their parts . xxmaj most often innetwork analysis the edges are given . xxmaj however in many systems it is xxunk impossible to measure the network directly . xxmaj examples of latent xxunk economic interactions linking financial instruments and patterns xxunk in gang violence . xxmaj in these cases we are limited to noisyobservations of events associated with each node . xxmaj to enable analysis of xxunk networks we develop a probabilistic model that xxunk point processes with random graph models . xxmaj we show how thepoisson superposition principle enables an elegant auxiliary xxunk and a fullybayesian parallel inference algorithm . xxmaj we xxunk new model empirically on several datasets .,xxbos xxmaj depth sensing devices have created various new applications in scientific andcommercial research with the advent of xxmaj microsoft xxmaj kinect and xxup pmd xxmaj photon xxunk cameras . xxmaj most of these applications require the depth cameras to xxunk . xxmaj however traditional calibration methods using a xxunk not work very well for depth cameras due to the low image resolution . xxmaj inthis paper we propose a depth calibration scheme which excels in xxunk calibration parameters when only a handful of corners and xxunk are available . xxmaj we exploit the noise properties of xxup pmd devices to xxunk measurements and perform camera calibration using the denoised depth asan additional set of measurements . xxmaj our synthetic and real experiments show thatour depth denoising and depth based calibration scheme provides significantlybetter results than traditional calibration methods .\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T12:47:33.499993Z",
     "start_time": "2020-01-13T12:47:29.638987Z"
    }
   },
   "outputs": [],
   "source": [
    "learn = language_model_learner(data2, AWD_LSTM, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T12:48:25.624346Z",
     "start_time": "2020-01-13T12:47:33.502989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='99' class='' max='5161', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      1.92% [99/5161 00:45<38:59 13.5511]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T12:48:29.956677Z",
     "start_time": "2020-01-13T12:48:29.124075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:36:18.773279Z",
     "start_time": "2020-01-13T12:48:35.996418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.897196</td>\n",
       "      <td>4.593517</td>\n",
       "      <td>0.273684</td>\n",
       "      <td>1:47:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:36:25.189846Z",
     "start_time": "2020-01-13T14:36:18.778271Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.save('stage-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:43:31.904203Z",
     "start_time": "2020-01-13T14:43:31.117291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Computer vision algorithms are based on large scale image restoration based on the basis of feature descriptors . However it is often in a very general way that the images are learned from a human body and not the background . In this paper we propose a novel text superresolution method that utilizes a large scale of the input . The image is trained by combining a single image pixel with an endtoend trainable accuracy . The image image is trained with an image and the decoder is fused with generalized image patches inwhich the image is encoded'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('Computer vision',temperature=.75,n_words=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:44:47.652407Z",
     "start_time": "2020-01-13T14:44:46.825603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Annotators using RNN have a limited number of main features . In this paper we describe the frequency of patient conceptual units as they have a high probability of the amount of labeled data . We propose a series of local features which represent the latent representations of the cells . In detail we analyze the the of the acoustic features in the training corpus . We describe a number of parameters and a single different neuron without explicitly describing the target task . We show that the ability to informative sequence . We provide a first'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('Annotators using RNN',temperature=.75,n_words=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:49:08.682538Z",
     "start_time": "2020-01-13T14:49:07.843826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jithin is a  problem that has neither been described in the past or proofofconcept areas . The notion of a formal digital device has been widely it has been used in efficient verification to better understand the data . However it is still unclear whether the issue of the system can be solved using genetic algorithms and distinguishing it from the nature of the algorithm . In this paper we present a novel approach that allows the use of the or like the vehicle i.e. a deep neural network to resolve stage Markov chain model . The approach'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('jithin is a ',temperature=.75,n_words=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:57:40.816149Z",
     "start_time": "2020-01-13T14:57:39.957433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The novel approach to the solution of a transformer  network is to perform feature extraction and processing and feature selection . Motivated by the problem of embedding the original deep convolutional network in this family of neural networks to replace deep neural networks with convolutional layers trained on a standard convolutional network for Convolutional Neural Networks cnns and Deep Convolutional Neural Networks cnns on the MNIST CIFAR10 imagenet dataset and Deep Neural Networks CNN and CNN architectures the proposed architecture is a single deep convolutional neural network CNN tuned to the best of'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('The novel approach to the solution of a transformer ',temperature=.75,n_words=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T15:01:53.591354Z",
     "start_time": "2020-01-13T15:01:52.796972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From the above we see that mayu is a   very important task in many applications . For example this article provides a very novel framework for estimating the number of pixels the distribution of objects . Some of this works significantly better than existing views . This paper presents a novel approach for characterizing the reliability of a value function that is a robot 's control connectivity . Our approach is based on the 3D light cloud and is a novel strategy to detect the objects of the objects in order to acquire a lossy image . The proposed method is utilized to\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('From the above we see that mayu is a  ',temperature=.75,n_words=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
